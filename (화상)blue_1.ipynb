{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUVKJ2trM1PKbhRYL1wwmp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/englissi/product/blob/main/(%ED%99%94%EC%83%81)blue_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install gradio\n",
        "!pip install speechrecognition\n",
        "!pip install pydub\n",
        "!pip install gtts\n"
      ],
      "metadata": {
        "id": "PXsYqmuUmvgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "AdJ9Y0wLmpBd",
        "outputId": "292e33f6-ef7d-489f-aa32-eb1c2ab38557"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Blocks' object has no attribute 'set_event_handler'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8b73c16bd58d>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradio_change\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_input_change\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Blocks' object has no attribute 'set_event_handler'"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from gtts import gTTS\n",
        "\n",
        "def transcribe_audio(audio):\n",
        "    recognizer = sr.Recognizer()\n",
        "    audio = AudioSegment.from_file(audio)\n",
        "    audio.export(\"temp.wav\", format=\"wav\")\n",
        "    with sr.AudioFile(\"temp.wav\") as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "        except sr.UnknownValueError:\n",
        "            text = \"Sorry, I could not understand the audio.\"\n",
        "        except sr.RequestError:\n",
        "            text = \"Sorry, there was an error with the speech recognition service.\"\n",
        "    os.remove(\"temp.wav\")\n",
        "    return text\n",
        "\n",
        "def speak_text(text):\n",
        "    tts = gTTS(text)\n",
        "    tts.save(\"question.mp3\")\n",
        "    return \"question.mp3\"\n",
        "\n",
        "questions = [\n",
        "    {\"context\": \"Let's talk about the story, My Dad's birthday party. Today is your dadâ€™s birthday. So you and your family will have a party tonight.\", \"question\": \"What will your mom do for the party?\", \"label\": \"Transcription of Mom's action\", \"answer\": \"She will cook the dinner.\"},\n",
        "    {\"context\": \"Look at the page 12 and 13.\", \"question\": \"What is she doing?\", \"label\": \"Transcription of Mom's action\", \"answer\": \"She is cooking.\"},\n",
        "    {\"context\": \"How about your brother?\", \"question\": \"What will he do for the party?\", \"label\": \"Transcription of Brother's action\", \"answer\": \"He will sing a birthday song.\"},\n",
        "    {\"context\": \"Look at the picture.\", \"question\": \"What is he doing?\", \"label\": \"Transcription of Brother's action\", \"answer\": \"He is singing.\"},\n",
        "    {\"context\": \"Okay, next,\", \"question\": \"How about you? What will you do for the party?\", \"label\": \"Transcription of Your action\", \"answer\": \"I will write a birthday card.\"},\n",
        "    {\"context\": \"Let's move on to the story 'Owls are special'. Owls are nocturnal.\", \"question\": \"When do they sleep?\", \"label\": \"Transcription of sleep time\", \"answer\": \"They sleep during the day.\"},\n",
        "    {\"context\": \"Look at the page 21, they have very special eyes.\", \"question\": \"So, what can they do with their special eyes?\", \"label\": \"Transcription of eye ability\", \"answer\": \"They can see well at night.\"},\n",
        "    {\"context\": \"Now, these questions are based on the story 'I will go shopping'. You have many things to buy. First, you need to buy a book. So, you will go to the bookstore. The bookstore is far away.\", \"question\": \"How will you go to the bookstore?\", \"label\": \"Transcription of transport method\", \"answer\": \"I will take the bus.\"},\n",
        "    {\"context\": \"Now you need to buy some bread.\", \"question\": \"Where will you go?\", \"label\": \"Transcription of place\", \"answer\": \"I will go to the bakery.\"},\n",
        "    {\"context\": \"Let's talk about the story 'Guide dogs'. Blind people can't see. But, they can still do things.\", \"question\": \"How can they do?\", \"label\": \"Transcription of how blind people do things\", \"answer\": \"They have guide dogs.\"},\n",
        "    {\"context\": \"Guide dogs help blind people with everything. For example, they bring things for them. They help them. They open doors for them.\", \"question\": \"What else can they do for them?\", \"label\": \"Transcription of other abilities\", \"answer\": \"They can turn the TV on and off.\"}\n",
        "]\n",
        "current_question = 0\n",
        "responses = []\n",
        "\n",
        "def next_question():\n",
        "    global current_question\n",
        "    if current_question < len(questions):\n",
        "        context = questions[current_question].get(\"context\", \"\")\n",
        "        question = questions[current_question][\"question\"]\n",
        "        full_text = f\"{context} {question}\"\n",
        "        question_audio = speak_text(full_text)\n",
        "        current_question += 1\n",
        "        return gr.update(value=question_audio, visible=True), gr.update(visible=True), questions[current_question-1][\"label\"], gr.update(visible=True), gr.update(visible=False)\n",
        "    else:\n",
        "        final_results = evaluate_responses()\n",
        "        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(value=final_results, visible=True)\n",
        "\n",
        "def save_response(audio):\n",
        "    transcription = transcribe_audio(audio)\n",
        "    responses.append(transcription)\n",
        "    return transcription\n",
        "\n",
        "def evaluate_responses():\n",
        "    result = \"<h2>Your Responses:</h2><br>\"\n",
        "    for i, question in enumerate(questions):\n",
        "        user_response = responses[i] if i < len(responses) else \"No response\"\n",
        "        result += f\"<b>Q:</b> {question['question']}<br><b>Your Answer:</b> {user_response}<br><br>\"\n",
        "    return result\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Interactive Questions\")\n",
        "\n",
        "    question_audio = gr.Audio(label=\"Question\", visible=False)\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Your answer\", visible=True)\n",
        "    transcription_output = gr.Textbox(label=\"Transcription\", visible=True)\n",
        "    btn_next = gr.Button(\"Next\", visible=True)\n",
        "    final_output = gr.HTML(visible=False)\n",
        "\n",
        "    def load_first_question():\n",
        "        return next_question()\n",
        "\n",
        "    demo.load(load_first_question, outputs=[question_audio, audio_input, transcription_output, btn_next, final_output])\n",
        "\n",
        "    btn_next.click(next_question, outputs=[question_audio, audio_input, transcription_output, btn_next, final_output])\n",
        "    audio_input.change(save_response, inputs=audio_input, outputs=transcription_output)\n",
        "\n",
        "    demo.launch()"
      ]
    }
  ]
}