{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBnrTwpY6iHKfOJxJ/FYbu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/englissi/product/blob/main/(%ED%99%94%EC%83%81)%20blue_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install gradio\n",
        "!pip install speechrecognition\n",
        "!pip install pydub\n",
        "!pip install gtts\n"
      ],
      "metadata": {
        "id": "PXsYqmuUmvgN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "AdJ9Y0wLmpBd",
        "outputId": "164cf002-7fb3-4243-8b23-3cbc1a199903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://2f9590deed2e6babc8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2f9590deed2e6babc8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from gtts import gTTS\n",
        "\n",
        "def transcribe_audio(audio):\n",
        "    recognizer = sr.Recognizer()\n",
        "    audio = AudioSegment.from_file(audio)\n",
        "    audio.export(\"temp.wav\", format=\"wav\")\n",
        "    with sr.AudioFile(\"temp.wav\") as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "        except sr.UnknownValueError:\n",
        "            text = \"Sorry, I could not understand the audio.\"\n",
        "        except sr.RequestError:\n",
        "            text = \"Sorry, there was an error with the speech recognition service.\"\n",
        "    os.remove(\"temp.wav\")\n",
        "    return text\n",
        "\n",
        "def speak_text(text):\n",
        "    tts = gTTS(text)\n",
        "    tts.save(\"question.mp3\")\n",
        "    return \"question.mp3\"\n",
        "\n",
        "questions = [\n",
        "    {\"context\": \"Let's talk about the story, My Dad's birthday party. Today is your dadâ€™s birthday. So you and your family will have a party tonight.\", \"question\": \"What will your mom do for the party?\", \"label\": \"Transcription of Mom's action\", \"answer\": \"She will cook the dinner.\"},\n",
        "    {\"context\": \"Look at the page 12 and 13.\", \"question\": \"What is she doing?\", \"label\": \"Transcription of Mom's action\", \"answer\": \"She is cooking.\"},\n",
        "    {\"context\": \"How about your brother?\", \"question\": \"What will he do for the party?\", \"label\": \"Transcription of Brother's action\", \"answer\": \"He will sing a birthday song.\"},\n",
        "    {\"context\": \"Look at the picture.\", \"question\": \"What is he doing?\", \"label\": \"Transcription of Brother's action\", \"answer\": \"He is singing.\"},\n",
        "    {\"context\": \"Okay, next,\", \"question\": \"How about you? What will you do for the party?\", \"label\": \"Transcription of Your action\", \"answer\": \"I will write a birthday card.\"},\n",
        "    {\"context\": \"Let's move on to the story 'Owls are special'. Owls are nocturnal.\", \"question\": \"When do they sleep?\", \"label\": \"Transcription of sleep time\", \"answer\": \"They sleep during the day.\"},\n",
        "    {\"context\": \"Look at the page 21, they have very special eyes.\", \"question\": \"So, what can they do with their special eyes?\", \"label\": \"Transcription of eye ability\", \"answer\": \"They can see well at night.\"},\n",
        "    {\"context\": \"Now, these questions are based on the story 'I will go shopping'. You have many things to buy. First, you need to buy a book. So, you will go to the bookstore. The bookstore is far away.\", \"question\": \"How will you go to the bookstore?\", \"label\": \"Transcription of transport method\", \"answer\": \"I will take the bus.\"},\n",
        "    {\"context\": \"Now you need to buy some bread.\", \"question\": \"Where will you go?\", \"label\": \"Transcription of place\", \"answer\": \"I will go to the bakery.\"},\n",
        "    {\"context\": \"Let's talk about the story 'Guide dogs'. Blind people can't see. But, they can still do things.\", \"question\": \"How can they do?\", \"label\": \"Transcription of how blind people do things\", \"answer\": \"They have guide dogs.\"},\n",
        "    {\"context\": \"Guide dogs help blind people with everything. For example, they bring things for them. They help them. They open doors for them.\", \"question\": \"What else can they do for them?\", \"label\": \"Transcription of other abilities\", \"answer\": \"They can turn the TV on and off.\"}\n",
        "]\n",
        "\n",
        "current_question = 0\n",
        "responses = []\n",
        "\n",
        "def next_question():\n",
        "    global current_question\n",
        "    if current_question < len(questions):\n",
        "        context = questions[current_question].get(\"context\", \"\")\n",
        "        question = questions[current_question][\"question\"]\n",
        "        full_text = f\"{context} {question}\"\n",
        "        question_audio = speak_text(full_text)\n",
        "        current_question += 1\n",
        "        return gr.update(value=question_audio, visible=True), gr.update(visible=True), questions[current_question-1][\"label\"], gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "    else:\n",
        "        final_results = evaluate_responses()\n",
        "        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(value=final_results, visible=True), gr.update(visible=True)\n",
        "\n",
        "def save_response(audio):\n",
        "    transcription = transcribe_audio(audio)\n",
        "    responses.append(transcription)\n",
        "    return transcription\n",
        "\n",
        "def evaluate_responses():\n",
        "    result = \"<h2>Your Responses:</h2><br>\"\n",
        "    for i, question in enumerate(questions):\n",
        "        user_response = responses[i] if i < len(responses) else \"No response\"\n",
        "        result += f\"<b>Q:</b> {question['question']}<br><b>Your Answer:</b> {user_response}<br><br>\"\n",
        "    return result\n",
        "\n",
        "def restart():\n",
        "    global current_question, responses\n",
        "    current_question = 0\n",
        "    responses = []\n",
        "    return load_first_question()\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Interactive Questions\")\n",
        "\n",
        "    question_audio = gr.Audio(label=\"Question\", visible=False)\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Your answer\", visible=True)\n",
        "    transcription_output = gr.Textbox(label=\"Transcription\", visible=True)\n",
        "    btn_next = gr.Button(\"Next\", visible=True)\n",
        "    btn_restart = gr.Button(\"Restart\", visible=False)\n",
        "    final_output = gr.HTML(visible=False)\n",
        "\n",
        "    def load_first_question():\n",
        "        return next_question()\n",
        "\n",
        "    demo.load(load_first_question, outputs=[question_audio, audio_input, transcription_output, btn_next, final_output, btn_restart])\n",
        "\n",
        "    btn_next.click(next_question, outputs=[question_audio, audio_input, transcription_output, btn_next, final_output, btn_restart])\n",
        "    audio_input.change(save_response, inputs=audio_input, outputs=transcription_output)\n",
        "    btn_restart.click(restart, outputs=[question_audio, audio_input, transcription_output, btn_next, final_output, btn_restart])\n",
        "\n",
        "    demo.launch()\n"
      ]
    }
  ]
}